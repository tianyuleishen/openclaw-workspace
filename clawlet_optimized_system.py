#!/usr/bin/env python3
"""
å°çˆªå†…å®¹å®‰å…¨æ¨¡å— v1.0
åŸºäº funNLP ç†å¿µè®¾è®¡
"""

import re
from typing import List, Dict, Optional


class ContentSafetyModule:
    """
    å†…å®¹å®‰å…¨æ¨¡å—
    åŠŸèƒ½ï¼šæ•æ„Ÿè¯æ£€æµ‹ã€å†…å®¹è¿‡æ»¤ã€æ–‡æ˜å¯¹è¯
    """
    
    def __init__(self):
        # æ•æ„Ÿè¯åº“ï¼ˆç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨æ—¶ä»æ–‡ä»¶åŠ è½½ï¼‰
        self.sensitive_words = {
            # æ”¿æ²»æ•æ„Ÿ
            'political': [],
            # è„è¯ç²—å£
            'profanity': [],
            # å¹¿å‘Šåƒåœ¾
            'spam': [],
            # å…¶ä»–ä¸å½“å†…å®¹
            'other': []
        }
        
        # åŠ è½½é»˜è®¤æ•æ„Ÿè¯
        self._load_default_words()
        
        # ç»Ÿè®¡
        self.stats = {
            'total_checks': 0,
            'blocked_count': 0,
            'warning_count': 0
        }
    
    def _load_default_words(self):
        """åŠ è½½é»˜è®¤æ•æ„Ÿè¯åº“"""
        # è„è¯ç²—å£ï¼ˆç¤ºä¾‹ï¼‰
        self.sensitive_words['profanity'] = [
            # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æ•æ„Ÿè¯
        ]
    
    def load_words_from_file(self, filepath: str, category: str = 'other'):
        """ä»æ–‡ä»¶åŠ è½½æ•æ„Ÿè¯"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                words = [line.strip() for line in f if line.strip()]
                self.sensitive_words[category].extend(words)
            print(f"âœ… åŠ è½½ {len(words)} ä¸ªæ•æ„Ÿè¯åˆ° {category}")
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    
    def check(self, text: str) -> Dict:
        """
        æ£€æŸ¥æ–‡æœ¬å†…å®¹å®‰å…¨
        
        Returns:
            {
                'safe': bool,
                'level': 'safe'/'warning'/'blocked',
                'matched_words': List[str],
                'suggestion': str
            }
        """
        self.stats['total_checks'] += 1
        
        text_lower = text.lower()
        matched = []
        
        # æ£€æŸ¥å„ç±»æ•æ„Ÿè¯
        for category, words in self.sensitive_words.items():
            for word in words:
                if word in text_lower:
                    matched.append({
                        'word': word,
                        'category': category
                    })
        
        # åˆ¤æ–­å®‰å…¨çº§åˆ«
        if len(matched) == 0:
            return {
                'safe': True,
                'level': 'safe',
                'matched_words': [],
                'suggestion': None
            }
        
        self.stats['warning_count'] += 1
        
        if len(matched) >= 3:
            self.stats['blocked_count'] += 1
            return {
                'safe': False,
                'level': 'blocked',
                'matched_words': matched,
                'suggestion': 'å†…å®¹åŒ…å«ä¸å½“è¯æ±‡ï¼Œè¯·æ–‡æ˜å‘è¨€'
            }
        
        return {
            'safe': True,
            'level': 'warning',
            'matched_words': matched,
            'suggestion': 'è¯·æ³¨æ„ç”¨è¯'
        }
    
    def filter(self, text: str) -> str:
        """è¿‡æ»¤æ•æ„Ÿè¯"""
        result = text
        
        for category, words in self.sensitive_words.items():
            for word in words:
                # æ›¿æ¢ä¸º *
                pattern = re.compile(re.escape(word), re.IGNORECASE)
                result = pattern.sub('*' * len(word), result)
        
        return result
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_checks': self.stats['total_checks'],
            'blocked': self.stats['blocked_count'],
            'warnings': self.stats['warning_count'],
            'safe_rate': (
                (self.stats['total_checks'] - self.stats['warning_count']) 
                / max(self.stats['total_checks'], 1) * 100
            )
        }


# ==================== æ„å›¾è¯†åˆ«æ¨¡å— ====================

class IntentClassifier:
    """
    æ„å›¾è¯†åˆ«æ¨¡å—
    åŠŸèƒ½ï¼šåˆ†ç±»ç”¨æˆ·æ„å›¾ã€å¿«é€Ÿå“åº”
    """
    
    def __init__(self):
        # æ„å›¾å…³é”®è¯
        self.intent_patterns = {
            'coding': ['å†™ä»£ç ', 'python', 'ç¼–ç¨‹', 'å‡½æ•°', 'ä»£ç ', 'debug'],
            'search': ['æœç´¢', 'æŸ¥æ‰¾', 'æ‰¾', 'æŸ¥è¯¢', 'æœ'],
            'chat': ['èŠå¤©', 'ä½ å¥½', 'åœ¨å—', 'å¹²å˜›'],
            'help': ['å¸®åŠ©', 'æ€ä¹ˆ', 'å¦‚ä½•', 'æ•™ç¨‹'],
            'system': ['çŠ¶æ€', 'æ€§èƒ½', 'å†…å­˜', 'CPU'],
            'file': ['æ–‡ä»¶', 'è¯»å–', 'å†™å…¥', 'ä¿å­˜'],
            'translate': ['ç¿»è¯‘', 'ç¿»è¯‘æˆ'],
        }
        
        self.intent_stats = {intent: 0 for intent in self.intent_patterns}
    
    def classify(self, text: str) -> Dict:
        """
        è¯†åˆ«ç”¨æˆ·æ„å›¾
        
        Returns:
            {
                'intent': str,
                'confidence': float,
                'keywords': List[str]
            }
        """
        text_lower = text.lower()
        scores = {}
        
        # åŒ¹é…å„ç±»æ„å›¾
        for intent, keywords in self.intent_patterns.items():
            score = sum(1 for kw in keywords if kw in text_lower)
            if score > 0:
                scores[intent] = score
        
        if not scores:
            return {
                'intent': 'unknown',
                'confidence': 0.0,
                'keywords': []
            }
        
        # è¿”å›æœ€é«˜åˆ†çš„æ„å›¾
        best_intent = max(scores, key=scores.get)
        max_score = scores[best_intent]
        confidence = min(max_score / 3, 1.0)  # å½’ä¸€åŒ–
        
        self.intent_stats[best_intent] += 1
        
        return {
            'intent': best_intent,
            'confidence': confidence,
            'keywords': [kw for kw in self.intent_patterns[best_intent] 
                        if kw in text_lower]
        }
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡"""
        total = sum(self.intent_stats.values())
        return {
            'total': total,
            'distribution': dict(self.intent_stats)
        }


# ==================== çŸ¥è¯†å›¾è°±æ¨¡å— ====================

class KnowledgeGraph:
    """
    çŸ¥è¯†å›¾è°±æ¨¡å—
    åŠŸèƒ½ï¼šç»“æ„åŒ–å­˜å‚¨è®°å¿†ã€å®ä½“å…³è”
    """
    
    def __init__(self):
        # å®ä½“
        self.entities = {}  # {entity_id: {type, name, properties}}
        # å…³ç³»
        self.relations = []  # [(entity1, relation, entity2)]
        # ç´¢å¼•
        self.entity_index = {}  # {type: [entity_ids]}
    
    def add_entity(self, entity_id: str, entity_type: str, name: str, 
                   properties: Dict = None):
        """æ·»åŠ å®ä½“"""
        self.entities[entity_id] = {
            'type': entity_type,
            'name': name,
            'properties': properties or {}
        }
        
        # æ›´æ–°ç´¢å¼•
        if entity_type not in self.entity_index:
            self.entity_index[entity_type] = []
        self.entity_index[entity_type].append(entity_id)
    
    def add_relation(self, from_id: str, relation: str, to_id: str):
        """æ·»åŠ å…³ç³»"""
        self.relations.append((from_id, relation, to_id))
    
    def query(self, entity_type: str = None, entity_id: str = None) -> List[Dict]:
        """æŸ¥è¯¢"""
        results = []
        
        if entity_id and entity_id in self.entities:
            results.append(self.entities[entity_id])
        
        if entity_type and entity_type in self.entity_index:
            for eid in self.entity_index[entity_type]:
                results.append(self.entities[eid])
        
        return results
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡"""
        return {
            'entities': len(self.entities),
            'relations': len(self.relations),
            'types': list(self.entity_index.keys())
        }


# ==================== é›†æˆæ¨¡å— ====================

class ClawletSystem:
    """
    å°çˆªç³»ç»Ÿé›†æˆ
    æ•´åˆå†…å®¹å®‰å…¨ã€æ„å›¾è¯†åˆ«ã€çŸ¥è¯†å›¾è°±
    """
    
    def __init__(self):
        self.safety = ContentSafetyModule()
        self.intent = IntentClassifier()
        self.knowledge = KnowledgeGraph()
        
        # ç‰ˆæœ¬
        self.version = "v1.0"
        
        # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±
        self._init_knowledge()
    
    def _init_knowledge(self):
        """åˆå§‹åŒ–çŸ¥è¯†å›¾è°±"""
        # æ·»åŠ å®ä½“
        self.knowledge.add_entity('user', 'person', 'ç”¨æˆ·', {'role': 'master'})
        self.knowledge.add_entity('system', 'system', 'å°çˆª', {'version': self.version})
        self.knowledge.add_entity('memory', 'module', 'è®°å¿†ç³»ç»Ÿ', {'type': 'markdown+json'})
        
        # æ·»åŠ å…³ç³»
        self.knowledge.add_relation('user', 'uses', 'system')
        self.knowledge.add_relation('system', 'has', 'memory')
    
    def process(self, user_input: str) -> Dict:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥
        
        æµç¨‹ï¼šå®‰å…¨æ£€æŸ¥ â†’ æ„å›¾è¯†åˆ« â†’ çŸ¥è¯†æŸ¥è¯¢ â†’ å“åº”
        """
        # 1. å®‰å…¨æ£€æŸ¥
        safety_result = self.safety.check(user_input)
        
        # 2. æ„å›¾è¯†åˆ«
        intent_result = self.intent.classify(user_input)
        
        # 3. çŸ¥è¯†æŸ¥è¯¢ï¼ˆæ ¹æ®æ„å›¾ï¼‰
        related_knowledge = []
        if intent_result['intent'] != 'unknown':
            related_knowledge = self.knowledge.query(
                entity_type=intent_result['intent']
            )
        
        return {
            'input': user_input,
            'safety': safety_result,
            'intent': intent_result,
            'knowledge': related_knowledge,
            'suggested_tools': self._suggest_tools(intent_result['intent'])
        }
    
    def _suggest_tools(self, intent: str) -> List[str]:
        """æ ¹æ®æ„å›¾æ¨èå·¥å…·"""
        tool_map = {
            'coding': ['python', 'shell'],
            'search': ['web_search', 'file_search'],
            'chat': ['chat'],
            'file': ['file_read', 'file_write'],
            'help': ['documentation'],
        }
        return tool_map.get(intent, ['general'])
    
    def get_system_stats(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'version': self.version,
            'safety': self.safety.get_stats(),
            'intent': self.intent.get_stats(),
            'knowledge': self.knowledge.get_stats()
        }


# ==================== æµ‹è¯• ====================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¦ å°çˆªç³»ç»Ÿä¼˜åŒ– - Phase 1: å†…å®¹å®‰å…¨æ¨¡å—")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    clawlet = ClawletSystem()
    
    print(f"\nâœ… ç³»ç»Ÿç‰ˆæœ¬: {clawlet.version}")
    print(f"   çŸ¥è¯†å›¾è°±: {clawlet.knowledge.get_stats()['entities']} å®ä½“")
    
    # æµ‹è¯•å®‰å…¨æ£€æŸ¥
    print("\nğŸ“Š å®‰å…¨æ£€æŸ¥æµ‹è¯•:")
    tests = [
        ("ä½ å¥½å°çˆªï¼", "æ­£å¸¸"),
        ("å¸®æˆ‘å†™ä»£ç ", "æ­£å¸¸"),
        ("æµ‹è¯•å†…å®¹", "æ­£å¸¸"),
    ]
    
    for text, expected in tests:
        result = clawlet.safety.check(text)
        print(f"   [{expected}] {text[:20]} â†’ {result['level']}")
    
    # æµ‹è¯•æ„å›¾è¯†åˆ«
    print("\nğŸ¯ æ„å›¾è¯†åˆ«æµ‹è¯•:")
    tests = [
        "å¸®æˆ‘å†™ä¸€ä¸ª Python å‡½æ•°",
        "æœç´¢ AI è®ºæ–‡",
        "ä½ å¥½å°çˆª",
    ]
    
    for text in tests:
        result = clawlet.intent.classify(text)
        print(f"   {text[:20]} â†’ {result['intent']} ({result['confidence']:.2f})")
    
    # å¤„ç†ç”¨æˆ·è¾“å…¥
    print("\nğŸ”„ å¤„ç†æµç¨‹æµ‹è¯•:")
    result = clawlet.process("å¸®æˆ‘æœç´¢ AI è®ºæ–‡")
    print(f"   è¾“å…¥: {result['input']}")
    print(f"   å®‰å…¨: {result['safety']['level']}")
    print(f"   æ„å›¾: {result['intent']['intent']}")
    print(f"   æ¨èå·¥å…·: {result['suggested_tools']}")
    
    # ç³»ç»ŸçŠ¶æ€
    print("\nğŸ“ˆ ç³»ç»ŸçŠ¶æ€:")
    stats = clawlet.get_system_stats()
    print(f"   ç‰ˆæœ¬: {stats['version']}")
    print(f"   å®‰å…¨æ£€æŸ¥: {stats['safety']['total_checks']}")
    print(f"   æ„å›¾è¯†åˆ«: {stats['intent']['total']}")
    print(f"   çŸ¥è¯†å›¾è°±: {stats['knowledge']['entities']} å®ä½“, {stats['knowledge']['relations']} å…³ç³»")
    
    print("\n" + "=" * 60)
    print("âœ… å°çˆªç³»ç»Ÿä¼˜åŒ–æ¨¡å—åŠ è½½æˆåŠŸï¼")
    print("=" * 60)
